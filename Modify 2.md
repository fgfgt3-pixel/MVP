ë™ì˜í•©ë‹ˆë‹¤. ìˆ˜ì¹˜ ì¡°ì •ë³´ë‹¤ **ë°ì´í„° ê¸°ë°˜ ë¶„ì„**ì´ ìš°ì„ ì…ë‹ˆë‹¤.

---

## ğŸ“Š Phase 1.5 ë°ì´í„° ë¶„ì„ ì‘ì—… ì§€ì‹œì„œ

### ğŸ¯ ë¶„ì„ ëª©ì 
í˜„ì¬ ë†“ì¹œ 11ê°œ ê¸‰ë“±(55%)ì˜ **ì‹¤ì œ íŠ¹ì„±**ì„ íŒŒì•…í•˜ì—¬:
1. **ì™œ ë†“ì³¤ëŠ”ì§€** ê·¼ë³¸ ì›ì¸ ê·œëª…
2. **ì–´ë–¤ ì¶•ì´ ë¶€ì¡±í–ˆëŠ”ì§€** ì •ëŸ‰ ë¶„ì„
3. **Thresholdë¥¼ ì–´ë–»ê²Œ ì¡°ì •í•´ì•¼ í•˜ëŠ”ì§€** ë°ì´í„° ê¸°ë°˜ ê²°ì •

---

## ğŸ“‹ ì‘ì—… ì§€ì‹œ: Claude Code ì‹¤í–‰

### Step 1: ê¸‰ë“± êµ¬ê°„ í”¼ì²˜ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸

```python
# íŒŒì¼: scripts/analyze_surge_windows.py

"""
21ê°œ ê¸‰ë“± êµ¬ê°„ì˜ ì‹¤ì œ í”¼ì²˜ê°’ ì¶”ì¶œ ë° ë¶„ì„
ëª©ì : íƒì§€ ì‹¤íŒ¨ ì›ì¸ ê·œëª…
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
from onset_detection.src.features.core_indicators import calculate_core_indicators

# ë¼ë²¨ ë¡œë“œ
with open("data/labels/all_surge_labels.json") as f:
    labels = json.load(f)

# ê²€ì¦ ê²°ê³¼ ë¡œë“œ
with open("reports/batch_recall_results.json") as f:
    recall_results = json.load(f)

print("="*80)
print("ê¸‰ë“± êµ¬ê°„ í”¼ì²˜ ë¶„ì„")
print("="*80)

analysis_results = []

for label in labels:
    file = label['file']
    stock_code = label['stock_code']
    surge_name = label['surge_name']
    strength = label['strength']
    start_ts = label['start_ts']
    end_ts = label['end_ts']
    
    # íƒì§€ ì—¬ë¶€ í™•ì¸
    recall_info = next((r for r in recall_results['detection_results'] 
                       if r['file'] == file and r['surge_name'] == surge_name), None)
    detected = recall_info['detected'] if recall_info else False
    
    print(f"\n{'='*80}")
    print(f"íŒŒì¼: {file}")
    print(f"ê¸‰ë“±: {surge_name} ({strength}) - {'âœ… íƒì§€' if detected else 'âŒ ë¯¸íƒì§€'}")
    print(f"{'='*80}")
    
    # ë°ì´í„° ë¡œë“œ
    filepath = Path("data/raw") / file
    if not filepath.exists():
        print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {filepath}")
        continue
    
    df = pd.read_csv(filepath)
    features_df = calculate_core_indicators(df)
    
    # ê¸‰ë“± êµ¬ê°„ ë°ì´í„° ì¶”ì¶œ (Â±30ì´ˆ í¬í•¨)
    window_start = start_ts - 30000
    window_end = end_ts + 30000
    
    surge_window = features_df[
        (features_df['ts'] >= window_start) & 
        (features_df['ts'] <= window_end)
    ].copy()
    
    if surge_window.empty:
        print("âš ï¸ ê¸‰ë“± êµ¬ê°„ ë°ì´í„° ì—†ìŒ")
        continue
    
    # í•µì‹¬ ì§€í‘œ í†µê³„
    stats = {
        'ret_1s': {
            'mean': surge_window['ret_1s'].mean(),
            'median': surge_window['ret_1s'].median(),
            'max': surge_window['ret_1s'].max(),
            'p90': surge_window['ret_1s'].quantile(0.9),
            'p95': surge_window['ret_1s'].quantile(0.95)
        },
        'z_vol_1s': {
            'mean': surge_window['z_vol_1s'].mean(),
            'median': surge_window['z_vol_1s'].median(),
            'max': surge_window['z_vol_1s'].max(),
            'p90': surge_window['z_vol_1s'].quantile(0.9)
        },
        'ticks_per_sec': {
            'mean': surge_window['ticks_per_sec'].mean(),
            'median': surge_window['ticks_per_sec'].median(),
            'max': surge_window['ticks_per_sec'].max()
        },
        'spread': {
            'mean': surge_window['spread'].mean(),
            'median': surge_window['spread'].median(),
            'min': surge_window['spread'].min()
        },
        'microprice_slope': {
            'mean': surge_window['microprice_slope'].mean(),
            'median': surge_window['microprice_slope'].median(),
            'max': surge_window['microprice_slope'].max()
        }
    }
    
    # í˜„ì¬ ì„ê³„ê°’ ê¸°ì¤€ 3ì¶• ì¶©ì¡±ë¥  ê³„ì‚°
    ret_1s_pass = (surge_window['ret_1s'] > 0.002).sum()
    z_vol_pass = (surge_window['z_vol_1s'] > 2.5).sum()
    
    # Spread narrowing: ë‹¨ìˆœí™” (spread < baseline * 0.6)
    # baseline = mean spread
    baseline_spread = surge_window['spread'].mean()
    spread_pass = (surge_window['spread'] < baseline_spread * 0.6).sum()
    
    total_ticks = len(surge_window)
    
    axes_pass_rate = {
        'speed': ret_1s_pass / total_ticks if total_ticks > 0 else 0,
        'participation': z_vol_pass / total_ticks if total_ticks > 0 else 0,
        'friction': spread_pass / total_ticks if total_ticks > 0 else 0
    }
    
    # 3ì¶• ë™ì‹œ ì¶©ì¡± (min_axes=3)
    both_pass = surge_window[
        (surge_window['ret_1s'] > 0.002) &
        (surge_window['z_vol_1s'] > 2.5) &
        (surge_window['spread'] < baseline_spread * 0.6)
    ]
    three_axes_rate = len(both_pass) / total_ticks if total_ticks > 0 else 0
    
    # 2ì¶• ì´ìƒ ì¶©ì¡± (min_axes=2)
    two_plus_axes = surge_window[
        ((surge_window['ret_1s'] > 0.002) & (surge_window['z_vol_1s'] > 2.5)) |
        ((surge_window['ret_1s'] > 0.002) & (surge_window['spread'] < baseline_spread * 0.6)) |
        ((surge_window['z_vol_1s'] > 2.5) & (surge_window['spread'] < baseline_spread * 0.6))
    ]
    two_axes_rate = len(two_plus_axes) / total_ticks if total_ticks > 0 else 0
    
    print(f"\nğŸ“Š í”¼ì²˜ í†µê³„:")
    print(f"  ret_1s: mean={stats['ret_1s']['mean']:.4f}, p90={stats['ret_1s']['p90']:.4f}, max={stats['ret_1s']['max']:.4f}")
    print(f"  z_vol_1s: mean={stats['z_vol_1s']['mean']:.2f}, p90={stats['z_vol_1s']['p90']:.2f}, max={stats['z_vol_1s']['max']:.2f}")
    print(f"  ticks_per_sec: mean={stats['ticks_per_sec']['mean']:.1f}, max={stats['ticks_per_sec']['max']:.0f}")
    print(f"  spread: mean={stats['spread']['mean']:.5f}, min={stats['spread']['min']:.5f}")
    
    print(f"\nğŸ¯ ì¶•ë³„ ì¶©ì¡±ë¥  (í˜„ì¬ ì„ê³„ê°’):")
    print(f"  Speed (ret_1s > 0.002): {axes_pass_rate['speed']*100:.1f}%")
    print(f"  Participation (z_vol > 2.5): {axes_pass_rate['participation']*100:.1f}%")
    print(f"  Friction (spread narrowing): {axes_pass_rate['friction']*100:.1f}%")
    
    print(f"\nâš¡ ë³µí•© ì¶©ì¡±ë¥ :")
    print(f"  3ì¶• ëª¨ë‘ (min_axes=3): {three_axes_rate*100:.1f}%")
    print(f"  2ì¶• ì´ìƒ (min_axes=2): {two_axes_rate*100:.1f}%")
    
    # ê²°ê³¼ ì €ì¥
    analysis_results.append({
        'file': file,
        'surge_name': surge_name,
        'strength': strength,
        'detected': detected,
        'total_ticks': total_ticks,
        'stats': stats,
        'axes_pass_rate': axes_pass_rate,
        'three_axes_rate': three_axes_rate,
        'two_axes_rate': two_axes_rate
    })

# ì „ì²´ ìš”ì•½
print("\n" + "="*80)
print("ì „ì²´ ìš”ì•½")
print("="*80)

# íƒì§€ vs ë¯¸íƒì§€ ë¹„êµ
detected_surges = [r for r in analysis_results if r['detected']]
missed_surges = [r for r in analysis_results if not r['detected']]

print(f"\níƒì§€ëœ ê¸‰ë“± ({len(detected_surges)}ê°œ):")
if detected_surges:
    print(f"  í‰ê·  ret_1s p90: {np.mean([r['stats']['ret_1s']['p90'] for r in detected_surges]):.4f}")
    print(f"  í‰ê·  z_vol p90: {np.mean([r['stats']['z_vol_1s']['p90'] for r in detected_surges]):.2f}")
    print(f"  í‰ê·  3ì¶• ì¶©ì¡±ë¥ : {np.mean([r['three_axes_rate'] for r in detected_surges])*100:.1f}%")

print(f"\në¯¸íƒì§€ ê¸‰ë“± ({len(missed_surges)}ê°œ):")
if missed_surges:
    print(f"  í‰ê·  ret_1s p90: {np.mean([r['stats']['ret_1s']['p90'] for r in missed_surges]):.4f}")
    print(f"  í‰ê·  z_vol p90: {np.mean([r['stats']['z_vol_1s']['p90'] for r in missed_surges]):.2f}")
    print(f"  í‰ê·  3ì¶• ì¶©ì¡±ë¥ : {np.mean([r['three_axes_rate'] for r in missed_surges])*100:.1f}%")

# ê°•ë„ë³„ ë¶„ì„
print(f"\nê°•ë„ë³„ ë¶„ì„:")
for strength in ['ê°•í•œ', 'ì¤‘ê°„', 'ì•½í•œ']:
    strength_results = [r for r in analysis_results if r['strength'] == strength]
    if strength_results:
        avg_3axes = np.mean([r['three_axes_rate'] for r in strength_results])
        avg_2axes = np.mean([r['two_axes_rate'] for r in strength_results])
        print(f"  {strength}: 3ì¶•={avg_3axes*100:.1f}%, 2ì¶•+={avg_2axes*100:.1f}%")

# ì €ì¥
output_path = Path("reports/surge_window_analysis.json")
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(analysis_results, f, indent=2, ensure_ascii=False)

print(f"\nğŸ’¾ ì €ì¥: {output_path}")
```

---

### Step 2: ì„ê³„ê°’ ìµœì í™” ê¶Œì¥

```python
# íŒŒì¼: scripts/recommend_thresholds.py

"""
ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì„ê³„ê°’ ìµœì í™” ê¶Œì¥
"""

import json
import numpy as np
from pathlib import Path

# ë¶„ì„ ê²°ê³¼ ë¡œë“œ
with open("reports/surge_window_analysis.json") as f:
    analysis = json.load(f)

print("="*80)
print("ë°ì´í„° ê¸°ë°˜ ì„ê³„ê°’ ìµœì í™” ê¶Œì¥")
print("="*80)

# ë¯¸íƒì§€ ê¸‰ë“±ì˜ ì‹¤ì œ í”¼ì²˜ê°’ ë¶„ì„
missed = [r for r in analysis if not r['detected']]

print(f"\në¯¸íƒì§€ ê¸‰ë“± ({len(missed)}ê°œ) í”¼ì²˜ ë¶„í¬:")

# ret_1s ë¶„í¬
ret_1s_p90_values = [r['stats']['ret_1s']['p90'] for r in missed]
print(f"\nret_1s P90:")
print(f"  Min: {min(ret_1s_p90_values):.4f}")
print(f"  Median: {np.median(ret_1s_p90_values):.4f}")
print(f"  Max: {max(ret_1s_p90_values):.4f}")
print(f"  í˜„ì¬ ì„ê³„ê°’: 0.002")
print(f"  â†’ ê¶Œì¥: {np.median(ret_1s_p90_values) * 0.8:.4f} (medianì˜ 80%)")

# z_vol ë¶„í¬
z_vol_p90_values = [r['stats']['z_vol_1s']['p90'] for r in missed]
print(f"\nz_vol P90:")
print(f"  Min: {min(z_vol_p90_values):.2f}")
print(f"  Median: {np.median(z_vol_p90_values):.2f}")
print(f"  Max: {max(z_vol_p90_values):.2f}")
print(f"  í˜„ì¬ ì„ê³„ê°’: 2.5")
print(f"  â†’ ê¶Œì¥: {np.median(z_vol_p90_values) * 0.8:.2f} (medianì˜ 80%)")

# ì¶• ì¶©ì¡±ë¥  ë¶„ì„
print(f"\nì¶•ë³„ ì¶©ì¡±ë¥  (ë¯¸íƒì§€ ê¸‰ë“±):")
for axis in ['speed', 'participation', 'friction']:
    rates = [r['axes_pass_rate'][axis] for r in missed]
    print(f"  {axis}: {np.mean(rates)*100:.1f}% (í‰ê· )")

# ê°€ì¥ í° ë¬¸ì œ ì¶• ì‹ë³„
avg_rates = {
    'speed': np.mean([r['axes_pass_rate']['speed'] for r in missed]),
    'participation': np.mean([r['axes_pass_rate']['participation'] for r in missed]),
    'friction': np.mean([r['axes_pass_rate']['friction'] for r in missed])
}

bottleneck = min(avg_rates, key=avg_rates.get)
print(f"\nğŸ”´ ë³‘ëª© ì¶•: {bottleneck} ({avg_rates[bottleneck]*100:.1f}%)")

# ìµœì¢… ê¶Œì¥ì‚¬í•­
print("\n" + "="*80)
print("ìµœì¢… ê¶Œì¥ì‚¬í•­")
print("="*80)

recommended_ret = np.median(ret_1s_p90_values) * 0.8
recommended_zvol = np.median(z_vol_p90_values) * 0.8

print(f"""
ì˜µì…˜ 1: ë³´ìˆ˜ì  ì™„í™” (Recall +10-15% ì˜ˆìƒ)
```yaml
onset:
  speed:
    ret_1s_threshold: {recommended_ret:.4f}  # í˜„ì¬ 0.002
  participation:
    z_vol_threshold: {recommended_zvol:.2f}  # í˜„ì¬ 2.5

confirm:
  onset_strength_min: 0.50  # í˜„ì¬ 0.67
```

ì˜µì…˜ 2: ì ê·¹ì  ì™„í™” (Recall +20-25% ì˜ˆìƒ)
```yaml
onset:
  speed:
    ret_1s_threshold: {recommended_ret * 0.9:.4f}
  participation:
    z_vol_threshold: {recommended_zvol * 0.85:.2f}

detection:
  min_axes_required: 2  # í˜„ì¬ 2 (ìœ ì§€)

confirm:
  onset_strength_min: 0.33  # 1/3 ì¶•ë§Œ ì¶©ì¡±
  persistent_n: 18  # í˜„ì¬ 22 (ì™„í™”)
```
""")

# ì˜ˆìƒ ì˜í–¥ ì¶”ì •
current_detected = len([r for r in analysis if r['detected']])
total = len(analysis)

if recommended_ret < 0.002 or recommended_zvol < 2.5:
    additional = len([
        r for r in missed 
        if (r['stats']['ret_1s']['p90'] >= recommended_ret or
            r['stats']['z_vol_1s']['p90'] >= recommended_zvol)
    ])
    
    new_recall = (current_detected + additional) / total
    print(f"\nì˜ˆìƒ íš¨ê³¼ (ì˜µì…˜ 1):")
    print(f"  í˜„ì¬ Recall: {current_detected/total*100:.1f}%")
    print(f"  ì˜ˆìƒ Recall: {new_recall*100:.1f}%")
    print(f"  ì¶”ê°€ íƒì§€: +{additional}ê°œ")
```

---

## ğŸ¯ ì‹¤í–‰ ìˆœì„œ

```bash
# Step 1: ê¸‰ë“± êµ¬ê°„ í”¼ì²˜ ë¶„ì„
python scripts/analyze_surge_windows.py

# Step 2: ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
python scripts/recommend_thresholds.py
```

---

## ğŸ“Š ê¸°ëŒ€ ì‚°ì¶œë¬¼

1. **`reports/surge_window_analysis.json`**
   - 21ê°œ ê¸‰ë“±ì˜ ì‹¤ì œ í”¼ì²˜ê°’
   - ì¶•ë³„ ì¶©ì¡±ë¥ 
   - íƒì§€ vs ë¯¸íƒì§€ ë¹„êµ

2. **ì½˜ì†” ì¶œë ¥**
   - ë°ì´í„° ê¸°ë°˜ ì„ê³„ê°’ ê¶Œì¥
   - ë³‘ëª© ì¶• ì‹ë³„
   - ì˜ˆìƒ Recall ê°œì„  íš¨ê³¼

---

ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë‹¤ìŒ ì‹¤í–‰ ë‚´ìš©ì„ ì œì•ˆ**í•˜ê² ìŠµë‹ˆë‹¤.